Namespace(batch_size=30, evaluation='True', max_seq_len=256)





EndToEnd(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(28996, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (top_model): CLSTopModel(
    (fc): Sequential(
      (0): Dropout(p=0.1, inplace=False)
      (1): Linear(in_features=768, out_features=1024, bias=True)
      (2): Tanh()
      (3): Dropout(p=0.1, inplace=False)
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Dropout(p=0.1, inplace=False)
      (7): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
Dataset statistics : 
Train / Val / Test : 636 / 90 / 129
Training model with params bs/seqlen : 30 256
Running train TRAIN
Running epoch 0

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.8665231996640773
Precision: [0.5688622754491018, 0.5681879557115852, 0.6484751203852327, 0.9596303501945526]
Recall: [0.24739583333333334, 0.9346956908040871, 0.5557083906464925, 0.9023258852737489]
F1 Score [0.3448275862068965, 0.7067517635203225, 0.5985185185185186, 0.9300963027813322]
F1 three cls 0.5500326227485792
Confusion Matrix:
[[  190.    16.     1.   127.]
 [  418.  2104.    28.  1153.]
 [    2.     2.   404.   215.]
 [  158.   129.   294. 13811.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.841025641025641
Precision: [0.5612244897959183, 0.4781326781326781, 0.5769230769230769, 0.9419180549302116]
Recall: [0.2, 0.8893967093235832, 0.4923413566739606, 0.8898341131433433]
F1 Score [0.2949061662198391, 0.6219239373601789, 0.5312868949232586, 0.915135608048994]
F1 three cls 0.4827056661677589
Confusion Matrix:
[[ 110.   14.    1.   71.]
 [ 250.  973.   11.  801.]
 [   1.    0.  225.  164.]
 [ 189.  107.  220. 8368.]]
Running epoch 1

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.9540205752676885
Precision: [0.8491547464239272, 0.8574265289912629, 0.827485380116959, 0.9812346661361979]
Recall: [0.8502604166666666, 0.9591292758773878, 0.7785419532324622, 0.9668104011498758]
F1 Score [0.8497072218607676, 0.9054309079471587, 0.8022678951098512, 0.9739691315365124]
F1 three cls 0.8524686749725925
Confusion Matrix:
[[  653.    10.     7.    99.]
 [   57.  2159.     9.   293.]
 [    1.     1.   566.   116.]
 [   57.    81.   145. 14798.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.9025641025641026
Precision: [0.7156133828996283, 0.7215384615384616, 0.6299559471365639, 0.9524584825789645]
Recall: [0.7, 0.8574040219378428, 0.6258205689277899, 0.9331135686941727]
F1 Score [0.707720588235294, 0.783625730994152, 0.6278814489571899, 0.9426867916420477]
F1 three cls 0.706409256062212
Confusion Matrix:
[[ 385.   19.    1.  133.]
 [  30.  938.    2.  330.]
 [   2.    0.  286.  166.]
 [ 133.  137.  168. 8775.]]
Running epoch 2

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.9447826999790049
Precision: [0.7760532150776053, 0.8780294000794596, 0.5987599645704162, 0.9937948152233866]
Recall: [0.9114583333333334, 0.9817858729453576, 0.9298486932599724, 0.9417222004442702]
F1 Score [0.8383233532934131, 0.927013422818792, 0.728448275862069, 0.9670580342167058]
F1 three cls 0.8312616839914247
Confusion Matrix:
[[  700.     9.     8.   185.]
 [   37.  2210.     9.   261.]
 [    5.     2.   676.   446.]
 [   26.    30.    34. 14414.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.8744893524554541
Precision: [0.6185852981969486, 0.6908177905308465, 0.43609865470852016, 0.9723464344551659]
Recall: [0.8109090909090909, 0.8802559414990859, 0.8512035010940919, 0.878668651637601]
F1 Score [0.7018095987411487, 0.7741157556270096, 0.5767234988880652, 0.9231370796559043]
F1 three cls 0.6842162844187412
Confusion Matrix:
[[ 446.   23.    2.  250.]
 [  32.  963.    2.  397.]
 [   1.    8.  389.  494.]
 [  71.  100.   64. 8263.]]
Running epoch 3

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.9783224858282595
Precision: [0.9445910290237467, 0.9614711033274956, 0.793063583815029, 0.9931330472103004]
Recall: [0.9322916666666666, 0.9755664149266993, 0.9436038514442916, 0.9826865281588919]
F1 Score [0.9384010484927915, 0.9684674751929438, 0.8618090452261307, 0.9878821713572624]
F1 three cls 0.9228925229706221
Confusion Matrix:
[[  716.    12.     2.    28.]
 [   18.  2196.     4.    66.]
 [    7.     1.   686.   171.]
 [   27.    42.    35. 15041.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.9010864841373316
Precision: [0.7343173431734318, 0.7716738197424893, 0.5140324963072378, 0.9562547966231773]
Recall: [0.7236363636363636, 0.8217550274223034, 0.7614879649890591, 0.9274776690769885]
F1 Score [0.7289377289377289, 0.7959274015050908, 0.6137566137566138, 0.9416464237516868]
F1 three cls 0.7128739147331445
Confusion Matrix:
[[ 398.   27.    1.  116.]
 [  18.  899.    2.  246.]
 [   2.    7.  348.  320.]
 [ 132.  161.  106. 8722.]]
Running epoch 4

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.9875078731891664
Precision: [0.964095744680851, 0.9722099691221879, 0.9166666666666666, 0.994436080382274]
Recall: [0.9440104166666666, 0.9791203909373611, 0.953232462173315, 0.9925519404155233]
F1 Score [0.9539473684210527, 0.9756529437804339, 0.9345920431557654, 0.9934931170911945]
F1 three cls 0.954730785119084
Confusion Matrix:
[[  725.     6.     3.    18.]
 [   21.  2204.     0.    42.]
 [    5.     4.   693.    54.]
 [   17.    37.    31. 15192.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.9086484137331595
Precision: [0.748062015503876, 0.8001752848378615, 0.5484429065743944, 0.9533980582524272]
Recall: [0.7018181818181818, 0.8345521023765996, 0.6936542669584245, 0.939812845597618]
F1 Score [0.724202626641651, 0.8170022371364652, 0.6125603864734299, 0.9465567098639819]
F1 three cls 0.7179217500838487
Confusion Matrix:
[[ 386.   21.    1.  108.]
 [  21.  913.    2.  205.]
 [   1.    7.  317.  253.]
 [ 142.  153.  137. 8838.]]
Running epoch 5

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.9904996850724334
Precision: [0.9681697612732095, 0.9677700348432056, 0.9746478873239437, 0.9957494114569709]
Recall: [0.9505208333333334, 0.9871168369613506, 0.951856946354883, 0.9948386253756697]
F1 Score [0.9592641261498029, 0.9773477017813942, 0.9631176061238691, 0.9952938100529446]
F1 three cls 0.9665764780183554
Confusion Matrix:
[[  730.     5.     4.    15.]
 [   21.  2222.     0.    53.]
 [    4.     3.   692.    11.]
 [   13.    21.    31. 15227.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.913168187744459
Precision: [0.7454212454212454, 0.7657657657657657, 0.6555819477434679, 0.9539551357733176]
Recall: [0.74, 0.8546617915904936, 0.6039387308533917, 0.9451297320289238]
F1 Score [0.7427007299270074, 0.8077753779697625, 0.6287015945330295, 0.9495219272474761]
F1 three cls 0.7263925674765997
Confusion Matrix:
[[ 407.   18.    1.  120.]
 [  28.  935.    2.  256.]
 [   1.    4.  276.  140.]
 [ 114.  137.  178. 8888.]]
Running epoch 6

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.9926516901112744
Precision: [0.9639175257731959, 0.9875167186803389, 0.9492656875834445, 0.9969903166710286]
Recall: [0.9739583333333334, 0.9840071079520213, 0.9779917469050894, 0.9955572977917156]
F1 Score [0.9689119170984456, 0.9857587894971073, 0.9634146341463413, 0.9962732919254659]
F1 three cls 0.9726951135806314
Confusion Matrix:
[[  748.     9.     2.    17.]
 [    7.  2215.     0.    21.]
 [    5.     3.   711.    30.]
 [    8.    24.    14. 15238.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.9084745762711864
Precision: [0.7252173913043478, 0.7615131578947368, 0.5892857142857143, 0.9590343019445051]
Recall: [0.7581818181818182, 0.8464351005484461, 0.7221006564551422, 0.9335389196086772]
F1 Score [0.7413333333333333, 0.8017316017316017, 0.6489675516224189, 0.9461148830692963]
F1 three cls 0.7306774955624512
Confusion Matrix:
[[ 417.   22.    1.  135.]
 [  22.  926.    1.  267.]
 [   1.    6.  330.  223.]
 [ 110.  140.  125. 8779.]]
Running epoch 7

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.9921792987612849
Precision: [0.9740932642487047, 0.9884290164663997, 0.9142125480153649, 0.997639653815893]
Recall: [0.9791666666666666, 0.9866725899600177, 0.9821182943603851, 0.9941199529596236]
F1 Score [0.9766233766233766, 0.9875500222321032, 0.9469496021220158, 0.9958766935008836]
F1 three cls 0.9703743336591653
Confusion Matrix:
[[  752.     7.     2.    11.]
 [    5.  2221.     0.    21.]
 [    6.     3.   714.    58.]
 [    5.    20.    11. 15216.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.9033463711429813
Precision: [0.7066895368782161, 0.7771236333052985, 0.5261538461538462, 0.9594847517340086]
Recall: [0.7490909090909091, 0.8446069469835467, 0.7483588621444202, 0.9267333049766057]
F1 Score [0.7272727272727273, 0.8094612352168199, 0.6178861788617886, 0.9428246876183263]
F1 three cls 0.7182067137837785
Confusion Matrix:
[[ 412.   25.    1.  145.]
 [  20.  924.    1.  244.]
 [   2.    6.  342.  300.]
 [ 116.  139.  113. 8715.]]
Running epoch 8

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.994331303800126
Precision: [0.9790849673202614, 0.9810822701275846, 0.977961432506887, 0.9978414442700158]
Recall: [0.9752604166666666, 0.9906708129720124, 0.9766162310866575, 0.9966679733437868]
F1 Score [0.9771689497716894, 0.9858532272325375, 0.9772883688919477, 0.9972543636007061]
F1 three cls 0.9801035152987249
Confusion Matrix:
[[  749.     5.     3.     8.]
 [    9.  2230.     3.    31.]
 [    4.     0.   710.    12.]
 [    6.    16.    11. 15255.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.9062146892655367
Precision: [0.7063903281519862, 0.7379471228615864, 0.6068702290076335, 0.9598508117595437]
Recall: [0.7436363636363637, 0.8674588665447898, 0.6958424507658644, 0.9304551254785198]
F1 Score [0.724534986713906, 0.7974789915966387, 0.6483180428134556, 0.9449244060475162]
F1 three cls 0.7234440070413335
Confusion Matrix:
[[ 409.   21.    1.  148.]
 [  29.  949.    1.  307.]
 [   2.    5.  318.  199.]
 [ 110.  119.  137. 8750.]]
Running epoch 9

Step 0 finished
Running test TRAIN
---Results---
Total tested: 19052.0
ACC: 0.994856183077892
Precision: [0.9804177545691906, 0.9871681415929203, 0.9636118598382749, 0.9982334467416907]
Recall: [0.9778645833333334, 0.9911150599733451, 0.9834938101788171, 0.9967986410557951]
F1 Score [0.9791395045632335, 0.9891376634892485, 0.9734513274336283, 0.9975155279503105]
F1 three cls 0.9805761651620367
Confusion Matrix:
[[  751.     5.     2.     8.]
 [    6.  2231.     2.    21.]
 [    6.     1.   715.    20.]
 [    5.    14.     8. 15257.]]
Running test VALIDATION
---Results---
Total tested: 11505.0
ACC: 0.9075184702303346
Precision: [0.7115716753022453, 0.7624489795918368, 0.5815602836879432, 0.9595053080879938]
Recall: [0.7490909090909091, 0.8537477148080439, 0.7177242888402626, 0.9322628668651638]
F1 Score [0.7298494242692649, 0.8055196205260888, 0.6425073457394711, 0.9456879348470957]
F1 three cls 0.7259587968449416
Confusion Matrix:
[[ 412.   22.    1.  144.]
 [  25.  934.    1.  265.]
 [   2.    6.  328.  228.]
 [ 111.  132.  127. 8767.]]
Epoch wise f1 val score three classes : [0.4827056661677589, 0.706409256062212, 0.6842162844187412, 0.7128739147331445, 0.7179217500838487, 0.7263925674765997, 0.7306774955624512, 0.7182067137837785, 0.7234440070413335, 0.7259587968449416]
Running test TEST
---Results---
Total tested: 16455.0
ACC: 0.9036766940139775
Precision: [0.6886657101865137, 0.7568321249302844, 0.5840336134453782, 0.952079088370689]
Recall: [0.7218045112781954, 0.8169777242624925, 0.6475155279503105, 0.935558027437894]
F1 Score [0.7048458149779735, 0.7857556456282571, 0.614138438880707, 0.9437462597247158]
F1 three cls 0.7015799664956459
Confusion Matrix:
[[  480.    27.     5.   185.]
 [   39.  1357.     6.   391.]
 [    2.     2.   417.   293.]
 [  144.   275.   216. 12616.]]

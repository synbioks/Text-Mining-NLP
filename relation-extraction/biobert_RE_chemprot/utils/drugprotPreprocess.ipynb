{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isdir, isfile, join, abspath\n",
    "mode = \"training\"\n",
    "dataset_dir = abspath(\"../datasets/drugprot-gs-training-development/{}/\".format(mode))\n",
    "\n",
    "abs_file = \"drugprot_training_abstracs.tsv\"\n",
    "ent_file = \"drugprot_training_entities.tsv\"\n",
    "rel_file = \"drugprot_training_relations.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mapper(label):\n",
    "    if \"GENE\" in label:\n",
    "        return \"GENE\"\n",
    "    if \"CHEMICAL\" in label:\n",
    "        return \"CHEMICAL\"\n",
    "    return label\n",
    "\n",
    "\n",
    "import csv\n",
    "ent_pth = []\n",
    "entities = {}\n",
    "\n",
    "with open(dataset_dir+ \"/\" + ent_file, \"r\", encoding=\"utf8\") as fin:\n",
    "    for row in csv.reader(fin, delimiter=\"\\t\"):\n",
    "        #print(row)\n",
    "        \n",
    "        doc_id = int(row[0])\n",
    "        ent_id = row[1]\n",
    "        \n",
    "        if doc_id not in entities:\n",
    "            entities[doc_id] = []\n",
    "            \n",
    "        entities[doc_id].append({\n",
    "            \"label\": label_mapper(row[2]),\n",
    "            \"start\": int(row[3]),\n",
    "            \"end\": int(row[4]),\n",
    "            \"id\": ent_id,\n",
    "            \"txt\": row[5]\n",
    "        })\n",
    "        #print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8db6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(entities))\n",
    "print(entities[list(entities.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c78c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "ent_pth = []\n",
    "relns = {}\n",
    "\n",
    "with open(dataset_dir+ \"/\" + rel_file, \"r\", encoding=\"utf8\") as fin:\n",
    "    for row in csv.reader(fin, delimiter=\"\\t\"):\n",
    "        doc_id = int(row[0])\n",
    "        reln = row[1]\n",
    "        arg1 = row[2][5:]\n",
    "        arg2 = row[3][5:]\n",
    "        #print(row)\n",
    "        #print(doc_id, reln, arg1, arg2)\n",
    "        \n",
    "        if doc_id not in relns:\n",
    "            relns[doc_id] = []\n",
    "        \n",
    "        relns[doc_id].append({\n",
    "            \"label\": reln,\n",
    "            \"id\": doc_id,\n",
    "            \"ent1\": arg1,\n",
    "            \"ent2\": arg2\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "relns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac4b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "ent_pth = []\n",
    "docs = {}\n",
    "\n",
    "with open(dataset_dir+ \"/\" + abs_file, \"r\", encoding=\"utf8\") as fin:\n",
    "    for row in csv.reader(fin, delimiter=\"\\t\"):\n",
    "        assert(len(row) == 3)\n",
    "        doc_id = int(row[0])\n",
    "        txt = row[1] + \"\\t\" + row[2]\n",
    "        \n",
    "        if doc_id not in relns:\n",
    "            docs[doc_id] = {}\n",
    "        \n",
    "        docs[doc_id] = {\n",
    "            \"id\": doc_id,\n",
    "            \"txt\": txt\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c61c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_len = [len(docs[doc][\"txt\"].split()) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(sents_len, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [docs[doc][\"txt\"] for doc in docs]\n",
    "sorted_sents = sorted(sents, key=lambda s: -len(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c1baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a2ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "tokenizer  = spacy.load(\"en_core_sci_sm\")\n",
    "# sent_spans = tokenizer(sorted_sents[0]).sents\n",
    "# print(sorted_sents[0])\n",
    "# for a in sent_spans:\n",
    "#     print(str(a) + \"$$$$\")\n",
    "#     print(a.start_char, a.end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_sent = docs[17512723][\"txt\"]\n",
    "sent_spans = tokenizer(curr_sent).sents\n",
    "print(curr_sent)\n",
    "print(\"\\n\\n\")\n",
    "for a in sent_spans:\n",
    "    print(str(a))\n",
    "    for ent in entities[17512723]:\n",
    "        if ent['start'] >= a.start_char and ent['start'] < a.end_char:\n",
    "            print(ent)\n",
    "            print(str(a)[:ent[\"start\"]-a.start_char] + \n",
    "                  \" $$ \" + \n",
    "                  str(a)[ent[\"start\"]-a.start_char:ent[\"end\"]-a.start_char] + \n",
    "                  \" $$ \" + \n",
    "                  str(a)[ent[\"end\"]-a.start_char:])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45b23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c74c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_sent = docs[17512723][\"txt\"]\n",
    "sent_spans = tokenizer(curr_sent).sents\n",
    "print(curr_sent)\n",
    "print(\"\\n\\n\")\n",
    "for a in sent_spans:\n",
    "    print(str(a))\n",
    "    for ent in entities[17512723]:\n",
    "        if ent['start'] >= a.start_char and ent['start'] < a.end_char:\n",
    "            print(ent)\n",
    "            print(str(a)[:ent[\"start\"]-a.start_char] + \n",
    "                  \" $$ \" + \n",
    "                  str(a)[ent[\"start\"]-a.start_char:ent[\"end\"]-a.start_char] + \n",
    "                  \" $$ \" + \n",
    "                  str(a)[ent[\"end\"]-a.start_char:])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183157e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942923a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_type_to_list = {\"GENE\":[], \"CHEMICAL\":[]}\n",
    "for ent in entities[17512723]:\n",
    "    ent_type_to_list[ent['label']].append(ent)\n",
    "    \n",
    "for t in ent_type_to_list:\n",
    "    print(t, ent_type_to_list[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b060d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce57ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "import copy\n",
    "for doc_id in list(docs.keys())[:10]:\n",
    "    curr_sent = docs[doc_id][\"txt\"]\n",
    "    sent_spans = tokenizer(curr_sent).sents\n",
    "    ent_type_to_list = {\"GENE\":[], \"CHEMICAL\":[]}\n",
    "    for ent in entities[doc_id]:\n",
    "        ent_type_to_list[ent['label']].append(ent)\n",
    "    \n",
    "    for span_id, a in enumerate(sent_spans):\n",
    "        print(doc_id, str(a))\n",
    "        sent_a = str(a)\n",
    "        ent_pairs = [(copy.deepcopy(ent1), copy.deepcopy(ent2)) \n",
    "                     for ent1 in ent_type_to_list[\"GENE\"] \n",
    "                     for ent2 in ent_type_to_list[\"CHEMICAL\"]]\n",
    "        for (ent1, ent2) in ent_pairs:\n",
    "            if (ent1['start'] >= a.start_char and ent1['start'] < a.end_char and \n",
    "                ent2['start'] >= a.start_char and ent2['start'] < a.end_char):\n",
    "                if ent1[\"start\"] > ent2[\"start\"]:\n",
    "                    ent1, ent2 = ent2, ent1\n",
    "                print(\"  ------\", ent1[\"txt\"], \"------\", ent2[\"txt\"], \"-------\")\n",
    "                new_sent = [\n",
    "                    sent_a[:ent1[\"start\"]-a.start_char],\n",
    "                    \"@\", ent1[\"label\"], \"$\",\n",
    "                    sent_a[ent1[\"end\"]-a.start_char:ent2[\"start\"]-a.start_char],\n",
    "                    \"@\", ent2[\"label\"], \"$\",\n",
    "                    sent_a[ent2[\"end\"]-a.start_char:],\n",
    "                    \"\\n\"\n",
    "                ]\n",
    "                new_sent = \"\".join(new_sent)\n",
    "                print(str(doc_id) + \"\\t\" + str(span_id) + \"\\t\" + new_sent)\n",
    "                assert(ent1[\"label\"] != ent2[\"label\"])\n",
    "    print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e446089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1bafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d46d01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78097f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5973b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "\n",
    "sents = []\n",
    "allsents_input = []\n",
    "\n",
    "with open(dataset_dir + \"/\" + \"re_input_all.tsv\", \"w\", encoding=\"utf8\") as ftest:\n",
    "    ftest.write(\"\\tDocId\\tSpanId\\tSentence\\tlbl\\n\")\n",
    "    for doc_id in tqdm(list(docs.keys())):\n",
    "        if doc_id not in relns:\n",
    "            #print(\"no relation found for this doc\")\n",
    "            continue\n",
    "        reln_list = relns[doc_id]    \n",
    "        curr_sent = docs[doc_id][\"txt\"]\n",
    "        sent_spans = tokenizer(curr_sent).sents\n",
    "        ent_type_to_list = {\"GENE\":[], \"CHEMICAL\":[]}\n",
    "        for ent in entities[doc_id]:\n",
    "            ent_type_to_list[ent['label']].append(ent)\n",
    "\n",
    "        for span_id, a in enumerate(sent_spans):\n",
    "            #print(doc_id, str(a))\n",
    "            sent_a = str(a)\n",
    "            ent_pairs = [(copy.deepcopy(ent1), copy.deepcopy(ent2)) \n",
    "                         for ent1 in ent_type_to_list[\"GENE\"] \n",
    "                         for ent2 in ent_type_to_list[\"CHEMICAL\"]]\n",
    "            for (ent1, ent2) in ent_pairs:\n",
    "                lbl = \"NA\"\n",
    "                for rel in reln_list:\n",
    "                    if ((ent1['id'] == rel[\"ent1\"] and ent2['id'] == rel[\"ent2\"]) or\n",
    "                        (ent1['id'] == rel[\"ent2\"] and ent2['id'] == rel[\"ent1\"])):\n",
    "                        lbl = rel[\"label\"]\n",
    "\n",
    "                if (ent1['start'] >= a.start_char and ent1['start'] < a.end_char and \n",
    "                    ent2['start'] >= a.start_char and ent2['start'] < a.end_char):\n",
    "\n",
    "                    if ent1[\"start\"] > ent2[\"start\"]:\n",
    "                        ent1, ent2 = ent2, ent1\n",
    "                    if ent1[\"start\"] == ent2[\"start\"] and lbl != \"NA\":\n",
    "                        print(\"warning: same start positiion\", doc_id)\n",
    "                        print(doc_id, \"  ------\", ent1[\"txt\"], \"------\", ent2[\"txt\"], \"-------\", a)\n",
    "                    new_sent = [\n",
    "                        sent_a[:ent1[\"start\"]-a.start_char],\n",
    "                        \"@\", ent1[\"label\"], \"$\",\n",
    "                        sent_a[ent1[\"end\"]-a.start_char:ent2[\"start\"]-a.start_char],\n",
    "                        \"@\", ent2[\"label\"], \"$\",\n",
    "                        sent_a[ent2[\"end\"]-a.start_char:]\n",
    "                    ]\n",
    "                    new_sent = \"\".join(new_sent)\n",
    "                    curr_out_sent = str(doc_id) + \"\\t\" + str(span_id) + \"\\t\" + new_sent + \"\\t\" + lbl + \"\\n\"\n",
    "                    allsents_input.append(curr_out_sent)\n",
    "                    ftest.write(curr_out_sent)\n",
    "                    assert(ent1[\"label\"] != ent2[\"label\"])\n",
    "                elif lbl != \"NA\" and (ent1['start'] >= a.start_char and ent1['start'] < a.end_char and \n",
    "                    not (ent2['start'] >= a.start_char and ent2['start'] < a.end_char)):\n",
    "                    print(doc_id, \"entities not in the same sentence\")\n",
    "        #print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14928362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade6902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad019315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0e786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6060735",
   "metadata": {},
   "outputs": [],
   "source": [
    "allsents_input[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006dfbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdec310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665aa93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae361c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df104546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac824e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063ce07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

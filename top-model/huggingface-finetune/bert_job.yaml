apiVersion: batch/v1
kind: Job
metadata:
  name: nikhil-fcn-8 # name this like <user>-<extra>
  namespace: sbks
spec:
  template:
    spec:
      nodeSelector:
        # nodeName: k8s-bharadia-03
        nautilus.io/region: ucsd
      containers:
      - name: bert-xl-alias
        image: nakumgaurav/sbks:dev8
        # image: tensorflow/tensorflow  
        command:
        - sh
        - -c
        args:
        - "bash /sbksvol/nikhil/sbks-ucsd-test/top-model/huggingface-finetune/run_test_v2.sh Species_miRNA_softmax_v10_lr5_6_wd3_ft5_pt5_2607_1 Species miRNA softmax_v10_lr5_6_wd3_ft5_pt5 > /sbksvol/nikhil/res_2607_1/Species_miRNA_softmax_v10_lr5_6_wd3_ft5_pt5.txt"
        resources:
          limits:
            memory: "8G"
            cpu: 1
            ephemeral-storage: "1G"
            nvidia.com/gpu: 1  # enable GPUs as needed
          requests:
            memory: "8G"
            cpu: 1
            ephemeral-storage: "1G"
            nvidia.com/gpu: 1  # must match the limit!
        volumeMounts:
          - mountPath: "/sbksvol"
            name: sbksvol
      restartPolicy: Never
      volumes:
        - name: sbksvol
          persistentVolumeClaim:
            claimName: sbksvol
  backoffLimit: 0  # no backoff; if pod fails, fail the job